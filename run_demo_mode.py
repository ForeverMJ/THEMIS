"""
Demo mode for Advanced Code Analysis system.

This script demonstrates the system capabilities without requiring API keys
by using mock responses and showing the analysis pipeline structure.
"""

import asyncio
import json
from pathlib import Path
from typing import Dict, List

# Import system components
try:
    from src.advanced_code_analysis.advanced_code_analyzer import AdvancedCodeAnalyzer
    from src.advanced_code_analysis.config import AdvancedAnalysisConfig
    from src.advanced_code_analysis.models import (
        BugType, AnalysisResult, AnalysisStrategy, ContextWindow
    )
    SYSTEM_AVAILABLE = True
except ImportError:
    SYSTEM_AVAILABLE = False
    print("âŒ Advanced analysis system components not available")


def load_text(path: Path) -> str:
    """Load text file with UTF-8 encoding."""
    if not path.exists():
        raise FileNotFoundError(f"Missing file: {path}")
    return path.read_text(encoding="utf-8")


def create_mock_analysis_result(issue_text: str, source_code: str) -> AnalysisResult:
    """Create a mock analysis result for demonstration."""
    
    # Analyze the issue text to determine likely bug type
    bug_type = "logic_error"
    if "api" in issue_text.lower() or "function" in issue_text.lower():
        bug_type = "api_issue"
    elif "performance" in issue_text.lower() or "slow" in issue_text.lower():
        bug_type = "performance"
    elif "boundary" in issue_text.lower() or "edge" in issue_text.lower():
        bug_type = "boundary_condition"
    
    # Create mock findings based on common patterns
    findings = []
    recommendations = []
    
    if "dot" in issue_text.lower() and "blueprint" in issue_text.lower():
        findings = [
            "æ£€æµ‹åˆ°Blueprintåç§°éªŒè¯é—®é¢˜",
            "å‘ç°å­—ç¬¦ä¸²å¤„ç†é€»è¾‘å¯èƒ½å­˜åœ¨ç¼ºé™·",
            "ç¼ºå°‘å¯¹ç‰¹æ®Šå­—ç¬¦çš„é€‚å½“éªŒè¯"
        ]
        recommendations = [
            "æ·»åŠ Blueprintåç§°éªŒè¯å‡½æ•°ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«ç‚¹å·",
            "å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†æœºåˆ¶",
            "æ·»åŠ å•å…ƒæµ‹è¯•è¦†ç›–è¾¹ç•Œæƒ…å†µ"
        ]
    elif "password" in issue_text.lower():
        findings = [
            "å¯†ç éªŒè¯å‡½æ•°å­˜åœ¨å¼‚å¸¸å¤„ç†é—®é¢˜",
            "é”™è¯¯å¤„ç†é€»è¾‘ä¸å®Œæ•´",
            "ç¼ºå°‘é€‚å½“çš„æ—¥å¿—è®°å½•"
        ]
        recommendations = [
            "ä¿®æ”¹validate_passwordå‡½æ•°çš„å¼‚å¸¸å¤„ç†",
            "æ·»åŠ try-catchå—å¤„ç†å¯†ç æ¯”è¾ƒå¤±è´¥",
            "å®ç°å®‰å…¨çš„é”™è¯¯æ¶ˆæ¯è¿”å›æœºåˆ¶"
        ]
    else:
        findings = [
            f"è¯†åˆ«ä¸º{bug_type}ç±»å‹çš„é—®é¢˜",
            "ä»£ç ç»“æ„åˆ†æå®Œæˆ",
            "å‘ç°æ½œåœ¨çš„æ”¹è¿›ç‚¹"
        ]
        recommendations = [
            "å»ºè®®è¿›è¡Œè¯¦ç»†çš„ä»£ç å®¡æŸ¥",
            "è€ƒè™‘æ·»åŠ æ›´å¤šçš„é”™è¯¯å¤„ç†",
            "å¢åŠ ç›¸å…³çš„æµ‹è¯•ç”¨ä¾‹"
        ]
    
    return AnalysisResult(
        bug_location="å¾…è¿›ä¸€æ­¥åˆ†æç¡®å®š",
        root_cause=f"åŸºäº{bug_type}æ¨¡å¼çš„åˆæ­¥åˆ†æ",
        fix_suggestion="è¯·å‚è€ƒæ¨èå»ºè®®è¿›è¡Œä¿®å¤",
        confidence=0.75,
        reasoning_chain=[
            "åˆ†æé—®é¢˜æè¿°å’Œä»£ç ç»“æ„",
            f"è¯†åˆ«ä¸º{bug_type}ç±»å‹é—®é¢˜",
            "ç”Ÿæˆç›¸åº”çš„ä¿®å¤å»ºè®®",
            "è¯„ä¼°åˆ†æç½®ä¿¡åº¦"
        ],
        supporting_evidence=[
            "é—®é¢˜æè¿°å…³é”®è¯åŒ¹é…",
            "ä»£ç æ¨¡å¼è¯†åˆ«",
            "å†å²æ¡ˆä¾‹å¯¹æ¯”"
        ]
    )


def demonstrate_bug_classification(issue_text: str):
    """Demonstrate bug classification capabilities."""
    
    print("ğŸ” Bug Classification Demo")
    print("-" * 40)
    
    # Simulate classification logic
    keywords = {
        "logic_error": ["logic", "condition", "if", "else", "loop"],
        "api_issue": ["api", "function", "method", "call", "parameter"],
        "performance": ["slow", "performance", "optimization", "speed"],
        "boundary_condition": ["boundary", "edge", "limit", "range"]
    }
    
    scores = {}
    for bug_type, words in keywords.items():
        score = sum(1 for word in words if word in issue_text.lower())
        scores[bug_type] = score
    
    best_match = max(scores, key=scores.get)
    confidence = scores[best_match] / len(keywords[best_match])
    
    print(f"ğŸ“Š Classification Results:")
    print(f"   Primary Type: {best_match}")
    print(f"   Confidence: {confidence:.2f}")
    print(f"   All Scores: {scores}")
    
    return best_match, confidence


def demonstrate_context_enhancement(source_code: str):
    """Demonstrate context enhancement capabilities."""
    
    print("\nğŸ“š Context Enhancement Demo")
    print("-" * 40)
    
    # Analyze code structure
    lines = source_code.split('\n')
    functions = [line.strip() for line in lines if line.strip().startswith('def ')]
    classes = [line.strip() for line in lines if line.strip().startswith('class ')]
    imports = [line.strip() for line in lines if line.strip().startswith(('import ', 'from '))]
    
    print(f"ğŸ“Š Code Structure Analysis:")
    print(f"   Total lines: {len(lines)}")
    print(f"   Functions: {len(functions)}")
    print(f"   Classes: {len(classes)}")
    print(f"   Imports: {len(imports)}")
    
    if functions:
        print(f"   Function examples: {functions[:3]}")
    if classes:
        print(f"   Class examples: {classes[:2]}")
    if imports:
        print(f"   Import examples: {imports[:3]}")
    
    # Estimate context complexity
    complexity_score = len(functions) * 2 + len(classes) * 3 + len(imports)
    print(f"   Complexity Score: {complexity_score}")
    
    return {
        'total_lines': len(lines),
        'functions': len(functions),
        'classes': len(classes),
        'imports': len(imports),
        'complexity_score': complexity_score
    }


def demonstrate_pattern_matching(issue_text: str, source_code: str):
    """Demonstrate pattern matching capabilities."""
    
    print("\nğŸ¯ Pattern Matching Demo")
    print("-" * 40)
    
    # Common bug patterns
    patterns = {
        "assignment_error": ["=", "==", "assign"],
        "null_pointer": ["None", "null", "NoneType"],
        "type_error": ["type", "TypeError", "isinstance"],
        "index_error": ["index", "IndexError", "list"],
        "validation_error": ["validate", "check", "verify"]
    }
    
    detected_patterns = []
    for pattern_name, keywords in patterns.items():
        if any(keyword in issue_text.lower() or keyword in source_code.lower() 
               for keyword in keywords):
            detected_patterns.append(pattern_name)
    
    print(f"ğŸ” Detected Patterns:")
    if detected_patterns:
        for pattern in detected_patterns:
            print(f"   âœ“ {pattern}")
    else:
        print("   No specific patterns detected")
    
    # Suggest analysis strategies
    print(f"\nğŸ’¡ Suggested Analysis Strategies:")
    if "validation_error" in detected_patterns:
        print("   â€¢ Focus on input validation logic")
        print("   â€¢ Check error handling mechanisms")
    if "type_error" in detected_patterns:
        print("   â€¢ Analyze type conversions")
        print("   â€¢ Review function signatures")
    if not detected_patterns:
        print("   â€¢ General code review approach")
        print("   â€¢ Structural analysis recommended")
    
    return detected_patterns


def demonstrate_multi_round_reasoning(issue_text: str):
    """Demonstrate multi-round reasoning capabilities."""
    
    print("\nğŸ§  Multi-Round Reasoning Demo")
    print("-" * 40)
    
    reasoning_steps = [
        "åˆå§‹é—®é¢˜åˆ†æï¼šç†è§£ç”¨æˆ·æè¿°çš„é—®é¢˜",
        "ä»£ç ç»“æ„åˆ†æï¼šè¯†åˆ«ç›¸å…³çš„ä»£ç ç»„ä»¶",
        "æ¨¡å¼åŒ¹é…ï¼šæŸ¥æ‰¾å·²çŸ¥çš„bugæ¨¡å¼",
        "ä¸Šä¸‹æ–‡æ”¶é›†ï¼šæ”¶é›†ç›¸å…³çš„ä»£ç ä¸Šä¸‹æ–‡",
        "å‡è®¾ç”Ÿæˆï¼šåŸºäºåˆ†æç”Ÿæˆå¯èƒ½çš„åŸå› ",
        "éªŒè¯å‡è®¾ï¼šæ£€æŸ¥å‡è®¾çš„åˆç†æ€§",
        "ç”Ÿæˆå»ºè®®ï¼šæä¾›å…·ä½“çš„ä¿®å¤å»ºè®®"
    ]
    
    print("ğŸ”„ Reasoning Process:")
    for i, step in enumerate(reasoning_steps, 1):
        print(f"   {i}. {step}")
    
    # Simulate confidence evolution
    confidence_evolution = [0.3, 0.5, 0.6, 0.7, 0.8, 0.75, 0.85]
    
    print(f"\nğŸ“ˆ Confidence Evolution:")
    for i, conf in enumerate(confidence_evolution, 1):
        print(f"   Round {i}: {conf:.2f}")
    
    final_confidence = confidence_evolution[-1]
    print(f"\nğŸ¯ Final Confidence: {final_confidence:.2f}")
    
    return reasoning_steps, final_confidence


async def run_demo():
    """Run the complete demo."""
    
    print("ğŸš€ Advanced Code Analysis System - Demo Mode")
    print("=" * 60)
    print("ğŸ“ Note: This demo uses mock responses to show system capabilities")
    print("   For real analysis, configure API keys and use run_quick_test.py")
    print()
    
    # Load experiment data
    base = Path(__file__).parent
    req_path = base / "experiment_data" / "issue.txt"
    code_path = base / "experiment_data" / "source_code.py"
    
    try:
        issue_text = load_text(req_path)
        source_code = load_text(code_path)
    except FileNotFoundError as e:
        print(f"âŒ Could not load experiment data: {e}")
        print("Using sample data for demo...")
        issue_text = "There's a validation error in the user input function. When users provide invalid data, the system crashes instead of showing an error message."
        source_code = """
def validate_user_input(data):
    if data is None:
        return False
    # Missing validation logic here
    return process_data(data)

def process_data(data):
    return data.upper()  # This will crash if data is not a string
"""
    
    print(f"ğŸ“‹ Demo Data:")
    print(f"   Issue: {issue_text[:100]}...")
    print(f"   Code length: {len(source_code)} characters")
    
    # Demonstrate each component
    bug_type, classification_confidence = demonstrate_bug_classification(issue_text)
    context_info = demonstrate_context_enhancement(source_code)
    detected_patterns = demonstrate_pattern_matching(issue_text, source_code)
    reasoning_steps, final_confidence = demonstrate_multi_round_reasoning(issue_text)
    
    # Generate mock analysis result
    print("\nğŸ“Š Complete Analysis Result")
    print("=" * 60)
    
    mock_result = create_mock_analysis_result(issue_text, source_code)
    
    print(f"ğŸ¯ Analysis Summary:")
    print(f"   Bug Type: {bug_type}")
    print(f"   Classification Confidence: {classification_confidence:.2f}")
    print(f"   Final Confidence: {final_confidence:.2f}")
    print(f"   Processing Time: 2.34s (simulated)")
    
    print(f"\nğŸ” Key Findings:")
    for i, finding in enumerate(mock_result.supporting_evidence, 1):
        print(f"   {i}. {finding}")
    
    print(f"\nğŸ’¡ Recommendations:")
    for i, rec in enumerate(mock_result.reasoning_chain, 1):
        print(f"   {i}. {rec}")
    
    print(f"\nğŸ§  System Capabilities Demonstrated:")
    print(f"   âœ“ Intelligent bug classification")
    print(f"   âœ“ Context-aware code analysis")
    print(f"   âœ“ Pattern-based problem detection")
    print(f"   âœ“ Multi-round reasoning process")
    print(f"   âœ“ Confidence scoring and validation")
    print(f"   âœ“ Structured recommendation generation")
    
    print(f"\nğŸš€ Next Steps:")
    print(f"   1. Configure API keys in .env file")
    print(f"   2. Run 'python run_quick_test.py' for real analysis")
    print(f"   3. Try 'python run_experiment_advanced.py' for comprehensive testing")
    print(f"   4. Use the system in your own code analysis workflows")


async def main():
    """Main demo function."""
    await run_demo()


if __name__ == "__main__":
    asyncio.run(main())