# THEMIS: Advanced Code Analysis and Spec-Change Consistency System

A comprehensive code analysis system that combines LLM-driven semantic understanding with structural graph analysis. The system features an Enhanced GraphManager for requirement-code consistency checking and an Advanced Code Analysis system for intelligent bug detection and classification.

## ğŸš€ New: Advanced Code Analysis System

The latest addition to THEMIS is a sophisticated LLM-powered code analysis system that provides:

- ğŸ§  **Intelligent Bug Classification** - Automatically categorizes issues and selects optimal analysis strategies
- ğŸ“š **Context Enhancement** - Provides rich code context and domain knowledge to LLMs
- ğŸ¯ **Pattern Learning** - Learns from successful cases to improve future analysis
- ğŸ”„ **Multi-Round Reasoning** - Uses iterative verification to improve accuracy
- ğŸ“Š **Confidence Scoring** - Provides reliability metrics for all analysis results

### Quick Start with Advanced Analysis

```bash
# Demo mode (no API key required)
python run_demo_mode.py

# Quick test (requires OpenAI API key)
python run_quick_test.py

# Three analysis modes:

# 1. Traditional workflow (KG â†’ Developer â†’ Judge)
python run_experiment_enhanced.py

# 2. Advanced LLM analysis only (semantic understanding)
python run_experiment_advanced.py

# 3. Integrated workflow (Advanced Analysis â†’ KG â†’ Developer â†’ Judge) â­ Recommended
python run_experiment_integrated.py

# Compare all three modes side-by-side
python compare_workflows.py
```

**Analysis Modes Explained:**

1. **Traditional Enhanced** (`run_experiment_enhanced.py`)
   - Uses Enhanced GraphManager for structural analysis
   - KG construction â†’ Developer revision â†’ Judge evaluation
   - Fast, rule-based approach

2. **Advanced Analysis** (`run_experiment_advanced.py`)
   - LLM-driven semantic understanding
   - Bug classification, concept mapping, pattern learning
   - Provides insights and recommendations (no automatic code revision)

3. **Integrated Workflow** (`run_experiment_integrated.py`) â­
   - **Best of both worlds**
   - Step 1: Advanced LLM analysis for semantic understanding
   - Step 2: KG construction enriched with LLM insights
   - Step 3: Developer uses both semantic and structural insights
   - Step 4: Judge validates the revised code
   - Combines intelligent understanding with automated revision

### ğŸ”„ Model Switching (New!)

Easily switch between different LLM models with a single command:

```bash
# View available models
python switch_model.py --list

# Switch to GPT-4o (recommended)
python switch_model.py gpt-4o

# Switch to Claude 3.5 Sonnet
python switch_model.py claude-3.5-sonnet

# Switch to GPT-3.5 (cost-effective)
python switch_model.py gpt-3.5-turbo
```

**Supported Models:**
- OpenAI: `gpt-4`, `gpt-4o`, `gpt-4o-mini`, `gpt-3.5-turbo`
- Anthropic: `claude-3.5-sonnet`, `claude-3-opus`, `claude-3-sonnet`, `claude-3-haiku`

**Documentation:**
- Quick Reference: `QUICK_MODEL_SWITCH.md`
- Detailed Guide: `MODEL_SWITCHING_GUIDE.md`
- ä¸­æ–‡è¯´æ˜: `æ¨¡å‹åˆ‡æ¢ä½¿ç”¨è¯´æ˜.md`

## System Architecture

The system now includes two complementary analysis approaches:

1. **Enhanced GraphManager** - Structural analysis using AST-derived graphs with requirement mapping
2. **Advanced Code Analysis** - LLM-driven semantic understanding with intelligent reasoning

Both systems can work independently or in integrated mode for maximum effectiveness.

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- `src/state.py` : AgentState å®šç¾©
- `src/graph_manager.py` : AST è§£æï¼‹è¦ä»¶ãƒãƒ¼ãƒ‰ä»˜ä¸
- `src/agents/developer.py` : LLM ã§ã‚³ãƒ¼ãƒ‰ä¿®æ­£
- `src/agents/judge.py` : KG ã‹ã‚‰çŸ›ç›¾æ¤œå‡º
- `src/main.py` : LangGraph ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- `src/baselines/` : vanilla / reflexion ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
- `run_experiment.py` : ææ¡ˆæ‰‹æ³•ã®å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `run_baseline.py` : vanilla å®Ÿè¡Œ
- `run_baseline_reflexion.py` : reflexion å®Ÿè¡Œ
- `tests/` : GraphManager ã®ãƒ†ã‚¹ãƒˆ

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
python -m venv .venv
. .venv/Scripts/activate  # Windows PowerShell: .\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

ç’°å¢ƒå¤‰æ•°ã« OpenAI API ã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:
```bash
setx OPENAI_API_KEY "your_key_here"  # Windows æ°¸ç¶š
# ã¾ãŸã¯ä¸€æ™‚çš„ã«
set OPENAI_API_KEY=your_key_here
```

## å®Ÿè¡Œä¾‹

### Advanced Code Analysis (New)
```bash
python run_demo_mode.py           # Demo mode - no API key needed
python run_quick_test.py          # Quick test of advanced analysis
python run_experiment_advanced.py # Comprehensive advanced analysis
python demo_integration.py        # System integration demo
```

### Traditional Analysis
```bash
python run_experiment.py          # ææ¡ˆæ‰‹æ³•ï¼ˆKG + Judge ãƒ«ãƒ¼ãƒ—ï¼‰
python run_experiment_enhanced.py # Enhanced GraphManager analysis
python run_baseline.py            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³1: ç›´æ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
python run_baseline_reflexion.py  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³2: Reflexion ãƒ«ãƒ¼ãƒ—
```

## ãƒ†ã‚¹ãƒˆ
```bash
pytest -q
```

## Configuration

### API Keys Setup
```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your API key
OPENAI_API_KEY=your_actual_api_key_here
```

### Analysis Strategies

The Advanced Code Analysis system supports multiple strategies:

- **AUTO_SELECT**: Automatically chooses the best strategy based on problem type
- **ADVANCED_ONLY**: Pure LLM-driven semantic analysis
- **GRAPH_ONLY**: Structure-based analysis using Enhanced GraphManager
- **INTEGRATED**: Combines both LLM and graph analysis for comprehensive results

## Documentation

- ğŸ“– [Advanced Analysis Guide](ADVANCED_ANALYSIS_GUIDE.md) - Comprehensive usage guide
- ğŸ§ª [Experiment Usage](EXPERIMENT_USAGE.md) - Detailed experiment instructions
- ğŸ”§ [Integration Summary](INTEGRATION_SUMMARY.md) - System integration details

## ãƒ¡ãƒ¢
- LLM ãƒ¢ãƒ‡ãƒ«åã¯ `src/main.py` ã‚„ `src/baselines/*` ã® `build_workflow`/`build_app` ã§å¤‰æ›´ã§ãã¾ã™ã€‚
- Judge ã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ KG ã¨ä¿®æ­£å¾Œ KG ã®ä¸¡æ–¹ã‚’å‚ç…§ã—ã€VIOLATES ã‚¨ãƒƒã‚¸ãŒã‚ã‚Œã°ãƒãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ã§å³ãƒ¬ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ã‚½ãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã¯æƒ…å ±ä¸è¶³ã®å ´åˆã«ä¿å®ˆçš„ãªææ¡ˆã‚’è¿”ã™ã“ã¨ãŒã‚ã‚‹ã®ã§ã€å¿…è¦ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„é–¾å€¤ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
- The Advanced Code Analysis system provides intelligent semantic understanding and can work with or without API keys (demo mode available).


## ğŸ”§ Troubleshooting

### Empty LLM Response

If you see:
```
Empty LLM response for conceptual matching; skipping.
```

**Cause**: Using `gpt-5-mini` which has unstable Responses API, or API key has quotes.

**Solution**:

1. **Check .env file** - Remove quotes from API key:
   ```bash
   # Wrong âŒ
   OPENAI_API_KEY="sk-proj-..."
   
   # Correct âœ…
   OPENAI_API_KEY=sk-proj-...
   ```

2. **Switch to stable model** (recommended):
   ```bash
   python switch_model.py gpt-4o-mini
   ```

See `GPT5_ISSUES.md` for detailed information.

### JSON Parsing Errors

If you encounter errors like:
```
Could not parse LLM response for conceptual matching: Expecting ',' delimiter
```

**Solution**: The system now has robust JSON parsing with automatic cleanup. If errors persist:

1. **Switch to a more stable model**:
   ```bash
   python switch_model.py gpt-4o
   ```

2. **Use traditional mode** (doesn't rely on LLM JSON parsing):
   ```bash
   python run_experiment_enhanced.py
   ```

3. **Check logs**: Errors are logged but won't interrupt the workflow

See `ä¿®å¤è¯´æ˜.md` for detailed fix information.

### API Key Issues

If you see "API key not found" warnings:

1. **Check your .env file**:
   ```bash
   # For OpenAI
   OPENAI_API_KEY=sk-proj-...
   
   # For Anthropic
   ANTHROPIC_API_KEY=sk-ant-...
   ```

2. **Verify the key is loaded**:
   ```bash
   python test_model_switch.py
   ```

### Model Not Working

If a specific model isn't working:

1. **List available models**:
   ```bash
   python switch_model.py --list
   ```

2. **Try a different model**:
   ```bash
   python switch_model.py gpt-3.5-turbo
   ```

3. **Check model compatibility**: Some models may not support all features

### Slow Performance

If analysis is taking too long:

1. **Use faster models**:
   ```bash
   python switch_model.py gpt-3.5-turbo  # Fastest
   python switch_model.py gpt-4o-mini    # Fast and good quality
   ```

2. **Use traditional mode** (faster than integrated):
   ```bash
   python run_experiment_enhanced.py
   ```

3. **Reduce context size**: Edit `src/advanced_code_analysis/config.py`:
   ```python
   max_context_tokens = 4000  # Reduce from 8000
   ```

### Comparison

For detailed workflow comparison and recommendations, see:
- `WORKFLOW_COMPARISON.md` - Detailed comparison of all three modes
- `è¿è¡ŒæŒ‡å—.txt` - Quick reference guide (Chinese)
- `compare_workflows.py` - Run all modes and compare results

## ğŸ“š Additional Resources

- **Model Switching**: `MODEL_SWITCHING_GUIDE.md`, `QUICK_MODEL_SWITCH.md`
- **Workflow Comparison**: `WORKFLOW_COMPARISON.md`
- **Fix Documentation**: `ä¿®å¤è¯´æ˜.md`, `æœ€ç»ˆä¿®å¤æ€»ç»“.md`
- **Quick Reference**: `è¿è¡ŒæŒ‡å—.txt`, `å¿«é€Ÿåˆ‡æ¢æ¨¡å‹.txt`
- **Troubleshooting**: `GPT5_ISSUES.md`
- **Environment Variables**: `ENV_VARIABLES_GUIDE.md`, `ENV_FLOW_DIAGRAM.txt`, `CONFIG_PRIORITY.md`
