#!/usr/bin/env python3
"""
å¿«é€Ÿæ¨¡å‹åˆ‡æ¢è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python switch_model.py gpt-4o
    python switch_model.py claude-3.5-sonnet
    python switch_model.py --list
"""

import sys
import os
from pathlib import Path
from src.model_switcher import ModelSwitcher, PRESET_MODELS


def update_env_file(model_name: str, provider: str):
    """æ›´æ–° .env æ–‡ä»¶ä¸­çš„æ¨¡å‹é…ç½®"""
    env_path = Path(".env")
    
    if not env_path.exists():
        # å¦‚æœ .env ä¸å­˜åœ¨ï¼Œä» .env.example å¤åˆ¶
        example_path = Path(".env.example")
        if example_path.exists():
            with open(example_path, 'r', encoding='utf-8') as f:
                content = f.read()
            with open(env_path, 'w', encoding='utf-8') as f:
                f.write(content)
    
    # è¯»å–ç°æœ‰å†…å®¹
    with open(env_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æ›´æ–°æˆ–æ·»åŠ æ¨¡å‹é…ç½®
    model_found = False
    provider_found = False
    new_lines = []
    
    for line in lines:
        if line.startswith('LLM_MODEL='):
            new_lines.append(f'LLM_MODEL={model_name}\n')
            model_found = True
        elif line.startswith('LLM_PROVIDER='):
            new_lines.append(f'LLM_PROVIDER={provider}\n')
            provider_found = True
        else:
            new_lines.append(line)
    
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œæ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾
    if not model_found:
        new_lines.append(f'\nLLM_MODEL={model_name}\n')
    if not provider_found:
        new_lines.append(f'LLM_PROVIDER={provider}\n')
    
    # å†™å›æ–‡ä»¶
    with open(env_path, 'w', encoding='utf-8') as f:
        f.writelines(new_lines)
    
    return env_path


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python switch_model.py <model_name>")
        print("æˆ–è€…: python switch_model.py --list")
        return 1
    
    switcher = ModelSwitcher()
    
    # åˆ—å‡ºå¯ç”¨æ¨¡å‹
    if sys.argv[1] in ['--list', '-l']:
        print("\n" + "="*70)
        print("å¯ç”¨çš„é¢„è®¾æ¨¡å‹:")
        print("="*70)
        
        # æŒ‰æä¾›å•†åˆ†ç»„
        openai_models = []
        anthropic_models = []
        
        for name, config in PRESET_MODELS.items():
            if config['provider'] == 'openai':
                openai_models.append((name, config))
            elif config['provider'] == 'anthropic':
                anthropic_models.append((name, config))
        
        print("\nğŸ¤– OpenAI æ¨¡å‹:")
        print("-" * 70)
        for name, config in openai_models:
            print(f"  â€¢ {name:20} â†’ {config['model_name']}")
        
        print("\nğŸ§  Anthropic æ¨¡å‹:")
        print("-" * 70)
        for name, config in anthropic_models:
            print(f"  â€¢ {name:20} â†’ {config['model_name']}")
        
        print("\n" + "="*70)
        print("ä½¿ç”¨æ–¹æ³•: python switch_model.py <model_name>")
        print("ä¾‹å¦‚: python switch_model.py gpt-4o")
        print("="*70 + "\n")
        return 0
    
    model_name = sys.argv[1]
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if model_name not in PRESET_MODELS:
        print(f"âŒ é”™è¯¯: æœªçŸ¥çš„æ¨¡å‹ '{model_name}'")
        print("\nå¯ç”¨çš„æ¨¡å‹:")
        for name in PRESET_MODELS.keys():
            print(f"  â€¢ {name}")
        print("\nä½¿ç”¨ 'python switch_model.py --list' æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
        return 1
    
    # è·å–æ¨¡å‹é…ç½®
    model_config = PRESET_MODELS[model_name]
    provider = model_config['provider']
    
    try:
        # æ›´æ–° .env æ–‡ä»¶
        env_path = update_env_file(model_name, provider)
        
        # éªŒè¯é…ç½®
        llm_config = switcher.get_model_config(model_name=model_name)
        
        print("\n" + "="*70)
        print("âœ… æ¨¡å‹åˆ‡æ¢æˆåŠŸ!")
        print("="*70)
        print(f"\nå½“å‰é…ç½®:")
        print(f"  â€¢ æ¨¡å‹åç§°: {model_name}")
        print(f"  â€¢ æä¾›å•†: {provider}")
        print(f"  â€¢ å®Œæ•´æ¨¡å‹å: {llm_config.model_name}")
        print(f"  â€¢ æœ€å¤§ä»¤ç‰Œæ•°: {llm_config.max_completion_tokens}")
        print(f"  â€¢ é…ç½®æ–‡ä»¶: {env_path}")
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key_var = f"{provider.upper()}_API_KEY"
        if not llm_config.api_key:
            print(f"\nâš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° {api_key_var}")
            print(f"   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®: {api_key_var}=your_key_here")
        else:
            key_preview = llm_config.api_key[:10] + "..." if len(llm_config.api_key) > 10 else "***"
            print(f"\nâœ“ APIå¯†é’¥å·²é…ç½®: {key_preview}")
        
        print("\n" + "="*70)
        print("ç°åœ¨å¯ä»¥è¿è¡Œä½ çš„è„šæœ¬ï¼Œå®ƒå°†ä½¿ç”¨æ–°çš„æ¨¡å‹é…ç½®")
        print("ä¾‹å¦‚: python run_experiment_enhanced.py")
        print("="*70 + "\n")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
